In this report we describe the parallel implementation of the FLAME Framework \cite{Coakley}. It updates the material presented in EURACE Delieverable D1.4 and presents specifically the developments of FLAME over the last period plus the results from assessing FLAME itself and the Full Integrated EURACE Model (FIEM). 

We cover some of the reasons for parallelisation and also give a detailed description of the approach being adopted. We give some details on the performance assessment tools that have been developed to aid the model developer in developing his model. We present some results from some performance assessments we have made of both the FLAME Framework using the EURACE Model and of the EURACE Model itseld.

There are many agent-based modelling systems. A detailed survey of such programs, systems and frameworks is given by Mangina \cite{Mangina}. Many of these systems are based on Java as their implementation language. Although a good language for web-based and some communications applications it is not one often used in the area of high performance computing. Similarly there are relatively few agent systems that address the problem of scalable parallel simulations.

Before considering the parallelisation of FLAME it is worth considering the characteristics of a software system than make it worth taking the time and effort to parallelise and the types of systems we are directing our efforts toward - for there are many different types of parallel system. It should also be remeber that FLAME is not the applications program to be parallelised. FLAME is but an applications program generator. It is this program that should exploit parallelisation. As describe in other papers and reports FLAME take a description of an agent-based model (the XMML definitions plus the associated function code) and generates a bespoke code for the particular application.

We are directing our attension to systems that are often referred to generically as \textit{high performance clusters}. This hides the multitude of differences in the hardware architectures of these systems - the types of processors - single or multi-code, the communications network between processors - specialised integrated or commodity. Collectively these systems can be considered \textit{Single Program Multiple Data - SPMD} architectures. Some characteristics of when to parallelise an application on these types of systems are:
\begin{itemize}
\item Code is practically incapable of running on one computer, memory requirements too great, run time too long
\item Code will be reused frequently - parallelisation is a large investment
\item Data structures are simple, calculations are local, easy to communicate and synchronize between processors
\end{itemize}
The converse should also be considered. When not to parallelise a code:
\begin{itemize}
\item Code will only be used once (or infrequently) - An efficient parallel code takes time to develop!
\item Current performance is acceptable and execution time is short
\item There will be frequent and significant code changes
\end{itemize}
In general terms it should also be remembered that some algorithms simply do not parallelise - there is insufficient independance in the component parts of a algorithm to utilise a multi-processor system. The
algorithm just does not map onto the system of distributed processes exchanging information through a
communications network. Often these types of algorithms are term \textit{closely coupled} or \textit{fine grained}.

As mentioned above the FLAME Framework is not the application - it is the application generator and hence the approach to parallelisation of FLAME generated applications must rely on the underlying architecture imposed on the generated application. Although this underlying architecture determines much of the potential parallelism in applications code might be utilised there must be parallelism in the application. We will discuss later the approach taken in FLAME to exploit parallelism.

From the list above and a knowledge of current system architectures locality and communication are key elements in achieving parallel perforance. However even if an application has many potentially independ task that could be executed in parallel the balance between the computational and communicatons load will greatly effect any parallel performance. These ideas can be expressed in terms of the granularity of application: what are the relative sizes of the computational and communications load each of these independent task.

It is clear that developing a scalable agent-based framework will be difficult. As mentioned above there are few examples none of which attempt to utilise the power of high performance systems such the Cray XT4 or the IBM BlueGene or the multitude of Beowulf type systems being offered by vendors. Agent systems such as SAMAS \cite{SAMAS},JADE \cite {JADE}, SIMJADE \cite{SIMJADE}, MACE3J \cite{MACE3J} and SPADES \cite{SPADES} have been used to demonstrate scalable agent computing but these have been relatively small simulations.

The starting point of FLAME is different from these systems - high performance computing was thought to be essential and thus the implementation language is C this opens the implementation to parallel programming tools and harnesses such as \textit{MPI} - Message Passing Interface and \textit{OpenMP} - Open Multi-Processing. These are the two main parallel processing tools used by the high performance computing community. 

MPI is a language-independent communications protocol used to program parallel computers. Both point-to-point and collective communication are supported. MPI is a message-passing application programmer interface, together with protocol and semantic specifications for how its features must behave in any implementation. MPI remains the dominant model used in high-performance computing today.

OpenMP is an application programming interface (API) that supports multi-platform shared memory multiprocessing programming in C, C++ and Fortran on many architectures, including Unix and Microsoft Windows platforms. It consists of a set of compiler directives, library routines, and environment variables that influence run-time behavior.

Although MPI will be used in the parallel implementation of FLAME many high performance systems use multi-core nodes - dual or even quad core processors. On these types of system OpenMP can provide an additional way of expoiting any potential parallelism in an application. 
