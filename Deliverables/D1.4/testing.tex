\subsection{Unit testing of the Message Board Library}

%As mentioned above the message boards are accessed by the FLAME framework via the Message Board Library Application Program Interface (\textit{libmboard} API). This provides the FLAME developer with a uniform interface to the functionality of the libmboard.
As the stability and correctness of the Message Board Library (\textit{libmboard}) is crucial for running FLAME models, extensive testing and validation steps have been incorporated into the development and maintenance workflow. 

We adopted the Test Driven Development approach whereby unit tests for every API routine and supporting components are written (based on pre-determined specifications) before the actual code. The relevant code is then written and validated by the tests. CUnit, a unit testing framework for C code has been used for this task as recommended by the UNICA unit.

Tests used during development are also reused and packaged as test suites for:
\begin{itemize}
\item Regression Tests -- All tests are executed before each code change is committed to the repository to ensure that nothing has been broken by the modification.
\item Portability Tests -- All tests are executed on a wide range of platforms before each code release.
\item Installation Tests -- The tests are provided along with the source code so user can validate the compilation on their platform before usage.
\end{itemize}

We also include an example simulation code which implements all features provided by the \textit{libmboard} API. This serves as a usage example as well as an additional test designed to exercises \textit{libmboard} routines in a more realistic scenario. This test is executed frequently on different platforms, especially before each code release.

\subsection{Unit testing of Timer Package}

During development of the timer package component of the dynamic load balancing library the functionality of the package has been tested using unit tests, based on CUnit as for the message board library.  The tests implemented are:

\begin{itemize}
 \item Single timer creation. Test that the first timer has correct handle and elapsed time.
 \item Multiple timer creation. Create 3 timers and check the handles and elapsed time are correct.
 \item Multiple timer start. Check that starting a timer while still running has no effect.
 \item Timer stop. Check that stopping a timer really does stop it.
 \item Timer reset. Check that resetting a timer sets its elapsed time to zero.
 \item Multiple timer stop. Check that stopping an already stopped time has no effect.
\end{itemize}

An example program to illustrate the use of a timer is also provided.

\subsection{Testing serial and parallel implementations}
It is important to ensure that applications generated by the FLAME framework execute \textsl{correctly} in both their serial and parallel modes. Because of the stochastic nature of the agent-based approach to modelling it is unrealistic to expect complex simulations to following exactly the solution path although general trends should be similar. However for some simple applications we can expect the serial and parallel implementations to produce exactly the same results throughout the simulation. Such example applications can be used to verify the correctness of both the serial and parallel implementations.

The \textsl{Circles Model} is one such application. The \textsl{Circles} agent is very simple. It has a position in two-dimensional space and a radius of influence. Each agent will react to its neighbours within its interaction radius repulsively. So given a sufficient simulation time the initial distribution of agents will tend to a field of uniformly spaced agents. Each agent has $x$, $y$, $fx$, $fy$ and $radius$ in its memory and has three states: outputdata, inputdata and move. The agents communicate via a single message board, $location$, which holds the agent $id$ and position. Given the simplicity of the agent it is possible to determine the final result of a number of ideal models.

A set of simple test models and problems have been developed based on the \textsl{Circles} agent. Each test has a \texttt{model.xmml} file and a set of initial data (\texttt{0.xml}).
\begin{description}
	\item [Test 1]: Model: single \textsl{Circles} agent type; Initial population of no agents. Expected result:
	\item [Test 2]: Model: single \textsl{Circles} agent type; Initial population of one agent at (0,0).
	\item [Test 3]: Model: Two \textsl{Circles} agent type; Initial population of agents at (-1,0) and (+,0).
	\item [Test 4]: Model: Four \textsl{Circles} agent type; Initial population of one agent at ($\pm$1,$\pm$1).
	\item [Test 5]: Model: Four \textsl{Circles} agent type; Initial population of one agent at (0,$\pm$1) and ($\pm$1,0).
	\item [Test 6]: Model: Four \textsl{Circles} agent type; Initial population of one agent at random positions.
	\end{description}
In each of these models the expected results can be specified and therefore they provide a very simple check of the implementation.

The \textsl{Circles} agent also provides a good mechanism to check the parallel implementation against the serial. Such is the nature of the model, the positions of the agents at each iteration of the simulation is independent of the order of calculation. As the order of calculation can not be easily prescribed in the parallel simulation we can use this characteristic to test the validity of the parallel implementation against the serial. We would expect to get the identical positions for each agent at every iteration of the simulation.

