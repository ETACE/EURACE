%\section{Tools for FLAME and Model Assessment}
\subsection{Static and Dynamic Analysis Tools}
EURACE has developed a very complex model in which there are many agents and many communications. The nested model directories contain 11 subdirectories and $\sim$50 XMML and C-code files. Checking the consistency of the model is a very difficult task. Although FLAME's parser will check the validity of $xml$ within the context of the DDT of FLAME tags, checking that messages are used in a consistent way is difficult.

There are many elements to the testing and assessment of an application. This is the harder in the case of FLAME as FLAME is a program generator. The project has agreed development standards for all software developed which includes FLAME and any C code component of the EURACE Model. These are detailed in other reports and on the EURACE Wiki. We have not only to verify that FLAME generates \textit{correct} code as defined in the FLAME Model definition but also that the generated code is also \textit{correct}.

Although there is a Unit Testing suite for EURACE its target is not FLAME - its has own set of test examples. Its target is the FLAME model functions. It addresses the verification and consistency of agent function calls once the model has been parsed by the \texttt{xparser} using the model XMML files.

However these \textit{unit test} do not check the consistency of the whole XMML model. A number of static and dynamic analysis tools have been developed to perform these types of analyses. These tools include the following analyses:
\begin{description}
	\item [analyses\_mode.py]: a static analysis of the FLAME model which gives detailed information on the components of a model: agent, function and messages types, number and sizes, a static communications table, a weighted communications table.
	\item [check\_message\_consistency.py]: a static consistency checker which compares the XMML definition with C code and ensures that the number and usage of messages is consistent.
	\item [The MM Package]: The \textit{MM} package is a dynamic to monitor message traffic in the simulation. It is a set additional directives included in the FLAME Templates which embedded in the application code that monitor all message traffic and outputs to an SQL data base. The data base can be post processed by the developed to assess the message traffic in the model. It also gathers information on the agent population in the simulation and the records of all function calls.
	\item [The Time Package]: The \textit{Timer} package described in Appendix \ref{app:timer-package} has been used to measure elapsed CPU time for functions and message board synchronisations. Knowing which functions take the longest time has helped to narrow the application of more detailed profiling tools such as \texttt{gprof} allowing for quicker identification of problems and possible solutions. Analysis of message board synchronisation times has shown that the message board implementation has provided excellent overlap of communication and computation.
\end{description}

\subsection {FLAME Verification}
Verification and validation of FLAME and its parallel implementation is again made difficult by its nature. We must verify and validation FLAME itself and we must also verify in some way the application generated by FLAME. It should be noted that FLAME has two distinct parts: the \texttt{xparser} which generates the application from the models XMML and C code files and \textit{The Message Board Library - libmboard} which is the underlying infrastructure that manages the inter-agent communications. \textit{libmboard} also provides an application to any parallel hardware through the MPI message passing interface.

\textit{libmboard} has is own set of unit tests and test programs. It has been developed using an agile test driven methodology. These are documented in the \textit{libmboard} documentation. Similarly the \texttt{xparser} has its own set of tests which are detailed in other reports.

For the developers we need to verify that FLAME is generating the model specified in the XMML and C code and that the execution of the generated application is \textit{correct}. Throughout the project we have gather a number of test examples which help verify the FLAME implementation. These test examples are model definitions and their associated C code. 

We have started to provide a set of \textit{simple} problems that enable us to do this. They need to be simple for the only way of checking that the code in correct is by very careful walk throughs. In Appendix~\ref{app:flameverification} we have described some of these very basic models that are used in verifying the FLAME generation process. As you will see these are very simple problems. There main characteristics being they exercise the FLAME infrastructure and we can determine the expected results of the simulation. By using these types of simple models we are able to verify that both the serial and parallel versions of the FLAME generated applications are \textit{correct} - in as much that they produce the expected results.

\subsection{Model Validation}
Validating the outputs of any simulation code generated by FLAME is in itself difficult. This will really require mining the outputs of the application and making comparisons with analytic or observer results. There are very few tools that can perform this task. A simple model validation tool. The \texttt{sim\_validator} uses an SQL data base of the simulations results to which it applies a set of \textit{simulation rules}.

The default file is \texttt{eurace.rules}. A snippet from the rules file:
\begin{quote}
\small\tt
::VARIABLES
\#Balance sheet: Firm
firm\_payment\_account = Firm(payment\_account)
firm\_cum\_revenue = Firm(cum\_revenue)
...
\#RULE VERIFIED
\#Firm:
abs( firm\_payment\_account + firm\_total\_value\_local\_inventory + 
firm\_total\_value\_capital\_stock - firm\_total\_debt - firm\_equity)< PRECISION
\end{quote}
In this snippet a number of variables are define: \texttt{firm\_payment\_account} for example is a reference to a Firm's memory variable \texttt{payment\_account}. Any number of variables can be defined. In the results select composite rules can be defined using these variables.

The tool applies these rules to the output of the simulation and reports any violations. There are currently 18 such rules in the EURACE validation file. The definition of these rules takes careful consideration by the model developers.



